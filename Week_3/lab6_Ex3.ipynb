{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cK-Mw13iDxlo",
        "outputId": "3ce02732-9cd8-4e80-b08e-2811151ef6b2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for ALG-LAB6:\n",
            "Time taken: 43.0175 seconds\n",
            "||âˆ‡f_lambda(x*)||: 7.3651\n",
            "||Ax* - y||^2: 2.7768\n",
            "||x* - x_orig||^2: 862.9025\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a3a27057d570>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtime_taken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_residual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nResults for {epochs} epochs:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Time taken: {time_taken:.4f} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-a3a27057d570>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "\n",
        "# Initialize parameters\n",
        "np.random.seed(1000)  # For repeatability\n",
        "N = 200               # Number of data points\n",
        "d = 1000              # Dimension of data causing failure in previous experiment\n",
        "lambda_reg = 0.001    # Regularization parameter\n",
        "eps = np.random.randn(N, 1)  # Random noise\n",
        "\n",
        "# Create data matrix and label vector\n",
        "A = np.random.randn(N, d)\n",
        "# Normalize the columns\n",
        "for j in range(A.shape[1]):\n",
        "    A[:, j] = A[:, j] / np.linalg.norm(A[:, j])\n",
        "\n",
        "x_orig = np.ones((d, 1))  # Original x\n",
        "y = np.dot(A, x_orig) + eps  # Generate labels\n",
        "\n",
        "# Initialize optimization variable\n",
        "x = np.zeros((d, 1))\n",
        "epochs = int(1e4)  # Number of epochs\n",
        "t = 1\n",
        "arr = np.arange(N)  # Index array\n",
        "\n",
        "# ALG-LAB6 Implementation\n",
        "start = timeit.default_timer()  # Start the timer\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    np.random.shuffle(arr)  # Shuffle every epoch\n",
        "    for i in np.nditer(arr):\n",
        "        # Compute gradient gi(x) for the ith data point\n",
        "        grad_i = -2 * A[i, :].reshape(-1, 1) * (y[i] - np.dot(A[i, :], x)) + 2 * lambda_reg * x\n",
        "        # Update x using x <- x - 1/t * g_i(x)\n",
        "        step = 1 / t\n",
        "        x = x - step * grad_i\n",
        "        t += 1\n",
        "        if t > 1e4:\n",
        "            t = 1\n",
        "\n",
        "alglab6_time = timeit.default_timer() - start  # Time taken for ALG-LAB6\n",
        "\n",
        "# Compute results\n",
        "norm_gradient = np.linalg.norm(2 * np.dot(A.T, np.dot(A, x) - y) + 2 * lambda_reg * x)\n",
        "norm_residual = np.linalg.norm(np.dot(A, x) - y)**2\n",
        "norm_diff = np.linalg.norm(x - x_orig)**2\n",
        "\n",
        "print(\"Results for ALG-LAB6:\")\n",
        "print(f\"Time taken: {alglab6_time:.4f} seconds\")\n",
        "print(f\"||\\u2207f_lambda(x*)||: {norm_gradient:.4f}\")\n",
        "print(f\"||Ax* - y||^2: {norm_residual:.4f}\")\n",
        "print(f\"||x* - x_orig||^2: {norm_diff:.4f}\")\n",
        "\n",
        "# Experiments with 1e6, 1e8, 1e10 epochs\n",
        "def run_experiment(epochs):\n",
        "    x = np.zeros((d, 1))\n",
        "    t = 1\n",
        "    start = timeit.default_timer()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        np.random.shuffle(arr)\n",
        "        for i in np.nditer(arr):\n",
        "            grad_i = -2 * A[i, :].reshape(-1, 1) * (y[i] - np.dot(A[i, :], x)) + 2 * lambda_reg * x\n",
        "            step = 1 / t\n",
        "            x = x - step * grad_i\n",
        "            t += 1\n",
        "            if t > 1e4:\n",
        "                t = 1\n",
        "\n",
        "    time_taken = timeit.default_timer() - start\n",
        "    norm_gradient = np.linalg.norm(2 * np.dot(A.T, np.dot(A, x) - y) + 2 * lambda_reg * x)\n",
        "    norm_residual = np.linalg.norm(np.dot(A, x) - y)**2\n",
        "    norm_diff = np.linalg.norm(x - x_orig)**2\n",
        "\n",
        "    return time_taken, norm_gradient, norm_residual, norm_diff\n",
        "\n",
        "for epochs in [int(1e6), int(1e8), int(1e10)]:\n",
        "    time_taken, norm_gradient, norm_residual, norm_diff = run_experiment(epochs)\n",
        "    print(f\"\\nResults for {epochs} epochs:\")\n",
        "    print(f\"Time taken: {time_taken:.4f} seconds\")\n",
        "    print(f\"||\\u2207f_lambda(x*)||: {norm_gradient:.4f}\")\n",
        "    print(f\"||Ax* - y||^2: {norm_residual:.4f}\")\n",
        "    print(f\"||x* - x_orig||^2: {norm_diff:.4f}\")\n",
        "\n",
        "# Experiments with varying lambda values\n",
        "def run_lambda_experiment(lambdas):\n",
        "    for lambda_val in lambdas:\n",
        "        x = np.zeros((d, 1))\n",
        "        t = 1\n",
        "        start = timeit.default_timer()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            np.random.shuffle(arr)\n",
        "            for i in np.nditer(arr):\n",
        "                grad_i = -2 * A[i, :].reshape(-1, 1) * (y[i] - np.dot(A[i, :], x)) + 2 * lambda_val * x\n",
        "                step = 1 / t\n",
        "                x = x - step * grad_i\n",
        "                t += 1\n",
        "                if t > 1e4:\n",
        "                    t = 1\n",
        "\n",
        "        time_taken = timeit.default_timer() - start\n",
        "        norm_gradient = np.linalg.norm(2 * np.dot(A.T, np.dot(A, x) - y) + 2 * lambda_val * x)\n",
        "        norm_residual = np.linalg.norm(np.dot(A, x) - y)**2\n",
        "        norm_diff = np.linalg.norm(x - x_orig)**2\n",
        "\n",
        "        print(f\"\\nResults for lambda = {lambda_val}:\")\n",
        "        print(f\"Time taken: {time_taken:.4f} seconds\")\n",
        "        print(f\"||\\u2207f_lambda(x*)||: {norm_gradient:.4f}\")\n",
        "        print(f\"||Ax* - y||^2: {norm_residual:.4f}\")\n",
        "        print(f\"||x* - x_orig||^2: {norm_diff:.4f}\")\n",
        "\n",
        "lambda_values = [1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
        "run_lambda_experiment(lambda_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WErkkqUdGTYJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}